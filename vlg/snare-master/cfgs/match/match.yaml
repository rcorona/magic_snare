hydra:
  run:
    dir: /data/abrar/3dgrounding/pointe_snare/lang_nerf/vlg/snare-master/${train.exps_folder}/${train.folder}
  sweep:
    dir: /data/abrar/3dgrounding/pointe_snare/lang_nerf/vlg/snare-master/${train.exps_folder}/
    subdir: ${train.folder}

root_dir: /data/abrar/3dgrounding/snare 

tag: default
seed: 0
debug: False

wandb:
  logger:
    entity: snare
    project: snare
    tags: []
    offline: False
    run_name: ${train.run_name}
  saver:
    upload: False
    monitor: 'val_acc'

data:
  fast_epoch: False
  amt_data: '${root_dir}/amt/'
  folds: 'folds_adversarial'

  clip_lang_feats: '/misery/abrar/3dgrounding/snare/data/langfeat-512-clipViT32.json'
  clip_img_feats: '/data/abrar/3dgrounding/snare/data/shapenet-clipViT32-frames.json'
  clip_img_feat_dir: '/data/abrar/3dgrounding/snare/data/shapenet-clipViT32-frames/'

  pointe_feats: '/data/abrar/3dgrounding/snare/data/pointe_feats/'

  voxel_reconstruction: False

  n_views: 8
  blind_only: False

  custom_renders: True
  custom_render_path: '${root_dir}/data/nmr_snare_render/shapenet_images_64_2.7/'

trainer: 
  max_steps: 10000000

train:
  exps_folder: 'snap'
  exp_name: 'match'
  folder: ${train.exp_name}
  run_name: ${train.aggregator.type}
  pretrained_model: ''
  model: 'single_cls'
  random_seed: 42
  log: False
  lr: 1e-3
  batch_size: 64
  max_epochs: 50
  load_from_last_ckpt: False
  dropout: 0.1
  normalize_feats: True
  pretrained_checkpoint: ""
  fc_projection_type: "fc"
  feats_backbone: "clip"
  val_freq: 100
  tiny_dataset: False
  shuffle: False

  pragmatic: False


  aggregator:
    type: 'maxpool'
    index: 0 # zeroth-view for 'index' aggregation type

  rotator:
    teacher_force: True # during training
    pretrained_cls: '${root_dir}/exp_may06/clip-single_cls-random_index/checkpoints/epoch=0041-val_acc=0.80161.ckpt'
    estimate_init_state: True
    estimate_final_state: True

  loss:
    est_weight: 1.0
    rot_weight: 1.0
    cls_weight: 0.2

val:
  adversarial_init_view: False

transformer: 
  freeze_legoformer: True
  freeze_clip: True
  lr: 0.001
  warmup_steps: 10000
  aggregate_lang: False
  xyz_embeddings: True
  skip_legoformer: False
  skip_clip: False
  optim: 'adamW'
  layers: 3
  head: 'transformer'

legoformer_transforms:
    mean: [0.5, 0.5, 0.5]
    std: [0.5, 0.5, 0.5]
    brightness: 0.4
    contrast: 0.4
    saturation: 0.4
    noise_std: 0.4
    train_rand_bg_color_range: [[225, 255], [225, 255], [225, 255]]
    test_rand_bg_color_range: [[240, 240], [240, 240], [240, 240]]
    bg_mode: random

legoformer_paths: 
  legoformer_m: '${root_dir}/checkpoints/epoch_10_step_118865.ckpt' # TODO Modify this if using different LegoFormer weights. 
  cfg: '${root_dir}/legoformer/config/'
  base_cfg: '${root_dir}/legoformer/config/base_config.yaml'

