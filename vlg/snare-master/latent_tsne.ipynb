{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run everything in this section to define functions and imports. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports. \n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from collections import Counter\n",
    "from nltk.corpus import wordnet as wn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the paths below for code to run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snare_path = '/home/rcorona/obj_part_lang/snare-master/amt/folds_adversarial'\n",
    "metadata_path = './data/metadata.csv'\n",
    "categories_path = './data/categories.synset.csv'\n",
    "lfn_feat_dir = './data/lfn_feats'\n",
    "clip_feat_dir = '/home/rcorona/dev/snare-master/data/shapenet-clipViT32-frames/'\n",
    "pixelnerf_feat_dir = '/home/rcorona/2022/lang_nerf/vlg/snare-master/data/pixelnerf_custom_feats'\n",
    "legoformer_feat_dir = '/home/rcorona/2022/lang_nerf/vlg/snare-master/data/legoformer_multiview_feats/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_snare_objs(): \n",
    "    \"\"\"\n",
    "    Get all ShapeNetSem object IDs for objects used in SNARE. \n",
    "    \"\"\"\n",
    "    train = json.load(open(os.path.join(snare_path, 'train.json')))\n",
    "    val = json.load(open(os.path.join(snare_path, 'val.json')))\n",
    "    test = json.load(open(os.path.join(snare_path, 'test.json')))\n",
    "\n",
    "    train_objs = set()\n",
    "    val_objs = set()\n",
    "    test_objs = set()\n",
    "\n",
    "    # Comb through snare files to collect unique set of ShapeNet objects. \n",
    "    snare_objs = set()\n",
    "\n",
    "    for obj_set, split in [(train_objs, train), (val_objs, val), (test_objs, test)]:\n",
    "        for datapoint in split: \n",
    "            for obj in datapoint['objects']:\n",
    "                obj_set.add(obj)\n",
    "\n",
    "    all_objs = train_objs | val_objs | test_objs\n",
    "\n",
    "    return list(all_objs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plot_labels(objs):\n",
    "    \"\"\"\n",
    "    Generate category labels for TSNE plot. \n",
    "    \"\"\"\n",
    "    \n",
    "    # Load all metadata for objects. \n",
    "    with open(metadata_path, 'r') as csvfile: \n",
    "        metadata = [row for row in csv.reader(csvfile)]\n",
    "        \n",
    "    # Get index of each object in metdata. \n",
    "    obj2synset = {m[0].replace('wss.', '').strip(): m[2].strip() for m in metadata}\n",
    "        \n",
    "    # Load synset word mappings. \n",
    "    with open(categories_path, 'r') as csvfile: \n",
    "        mappings = [row for row in csv.reader(csvfile)]\n",
    "        \n",
    "        # Mapping from synset to word. \n",
    "        s2w = {r[2].strip(): r[3].split(',')[0].strip() for r in mappings[1:]}    \n",
    "\n",
    "\n",
    "    # Get set of all synsets. \n",
    "    synset_codes = set([r[2].strip() for r in metadata[2:]])    \n",
    "    synsets = []\n",
    "\n",
    "    for s in synset_codes: \n",
    "        try: \n",
    "            synset = s2w[s]\n",
    "        except: \n",
    "            synset = 'None'\n",
    "            \n",
    "        synsets.append(synset)\n",
    "        \n",
    "\n",
    "    ## Get 10 most common object categories and filter out everything else.  \n",
    "    snare_synsets = []\n",
    "    counts = Counter()\n",
    "\n",
    "    # Count object categories. \n",
    "    for obj in objs:\n",
    "        synset = obj2synset[obj]\n",
    "\n",
    "        # Only count those with label. \n",
    "        if synset in s2w:\n",
    "            word = s2w[synset]\n",
    "            snare_synsets.append(word)\n",
    "            \n",
    "            # Update word count.\n",
    "            if not word == '': \n",
    "                counts[word] += 1\n",
    "        else: \n",
    "            snare_synsets.append(None)\n",
    "            \n",
    "    return snare_synsets, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lfn_features(objs):\n",
    "    \"\"\"\n",
    "    Given list of object IDs, load features for each object under LFN.  \n",
    "    \"\"\"\n",
    "    # Load all features and name order. \n",
    "    feats = []\n",
    "    \n",
    "    for obj in objs:\n",
    "        \n",
    "        # Load feature. \n",
    "        path = os.path.join(lfn_feat_dir, '{}.npy'.format(obj))\n",
    "        feat = feats.append(np.load(path))\n",
    "        \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clip_features(objs):\n",
    "    \"\"\"\n",
    "    Given list of object IDs, load features for each object under CLIP.  \n",
    "    \"\"\"\n",
    "    # Load all features and name order. \n",
    "    feats = []\n",
    "\n",
    "    for obj in objs:\n",
    "        \n",
    "        # Load image features for object. \n",
    "        path = os.path.join(clip_feat_dir, '{}.npy'.format(obj))\n",
    "        \n",
    "        # Load features for input views and take mean. \n",
    "        feat = np.mean(np.load(path)[6:], axis=0)\n",
    "        feats.append(feat)\n",
    "        \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_legoformer_features(objs):\n",
    "    \"\"\"\n",
    "    Given list of object IDs, load features for each object under LegoFormer.  \n",
    "    \"\"\"\n",
    "    # Load all features and name order. \n",
    "    feats = []\n",
    "\n",
    "    for obj in objs:\n",
    "        \n",
    "        # Load image features for object. \n",
    "        path = os.path.join(legoformer_feat_dir, '{}.npy'.format(obj))\n",
    "        \n",
    "        # Load and collapse dimension to consider as single feature. \n",
    "        feats.append(np.reshape(np.load(path), -1))\n",
    "        \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pixelnerf_features(objs):\n",
    "    \"\"\"\n",
    "    Given list of object IDs, load features for each object under PixelNeRF.  \n",
    "    \"\"\"\n",
    "    # Load all features and name order. \n",
    "    feats = []\n",
    "\n",
    "    print('Loading PixelNeRF features...')\n",
    "\n",
    "    for obj in tqdm(objs):\n",
    "        \n",
    "        # Load image features for object. \n",
    "        path = os.path.join(pixelnerf_feat_dir, '{}.npy'.format(obj))\n",
    "        \n",
    "        # Load features for input views and take mean. \n",
    "        feat = np.reshape(np.load(path), (8, 512, -1))\n",
    "        feat = np.mean(np.mean(feat, axis=0), axis=-1)\n",
    "        feats.append(feat)\n",
    "        \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def filter_by_top_k(counts, feats, objs, snare_synsets):\n",
    "    # Get 10 most common categories. \n",
    "    top10 = {t[0]: t[1] for t in counts.most_common(10)}\n",
    "\n",
    "    # Only keep objects in top-10 categories. \n",
    "    final_feats = []\n",
    "    final_labels = []\n",
    "\n",
    "    assert len(objs) == len(feats) and len(objs) == len(snare_synsets)\n",
    "\n",
    "    for i in range(len(objs)):\n",
    "        synset = snare_synsets[i]\n",
    "        \n",
    "        if synset in top10: \n",
    "            final_feats.append(feats[i])\n",
    "            final_labels.append(synset)\n",
    "            \n",
    "    # Create numpy array of features. \n",
    "    final_feats = np.stack(final_feats)\n",
    "    print('Final feature shape: {}'.format(final_feats.shape))\n",
    "    \n",
    "    return final_feats, final_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dimensionality with PCA. \n",
    "def gen_tsne_feats(final_feats):\n",
    "    pca_feats = PCA(n_components=3).fit_transform(final_feats)\n",
    "    print('PCA Feat shape: {}'.format(pca_feats.shape))\n",
    "\n",
    "    # Compute TSNE features.\n",
    "    tsne_feats = TSNE(n_components=2, random_state=0).fit_transform(pca_feats)\n",
    "    print('TSNE Feat shape: {}'.format(tsne_feats.shape))\n",
    "    \n",
    "    return tsne_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_plot(tsne_feats, final_labels, title):\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Plot the TSNE embeddings. \n",
    "    sns.scatterplot(x=tsne_feats[:,0], y=tsne_feats[:,1], hue=final_labels, palette=sns.color_palette(\"hls\", 10)).set(title=title)\n",
    "    plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate list of all ShapeNetSem objects used in SNARE. \n",
    "snare_objs = get_snare_objs()\n",
    "\n",
    "# Generate category labels for TSNE plot. \n",
    "synsets, counts = get_plot_labels(snare_objs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LFN Feature Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load LFN features. \n",
    "lfn_feats = load_lfn_features(snare_objs)\n",
    "\n",
    "# Filter features by top 10 most occurring categories. \n",
    "final_feats, final_labels = filter_by_top_k(counts, lfn_feats, snare_objs, synsets)\n",
    "\n",
    "# Generate TSNE features. \n",
    "tsne_feats = gen_tsne_feats(final_feats)\n",
    "\n",
    "# Visualize them. \n",
    "gen_plot(tsne_feats, final_labels, title='LFN TSNE Plot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLIP Feature Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load LFN features. \n",
    "clip_feats = load_clip_features(snare_objs)\n",
    "\n",
    "# Filter features by top 10 most occurring categories. \n",
    "final_feats, final_labels = filter_by_top_k(counts, clip_feats, snare_objs, synsets)\n",
    "\n",
    "# Generate TSNE features. \n",
    "tsne_feats = gen_tsne_feats(final_feats)\n",
    "\n",
    "# Visualize them. \n",
    "gen_plot(tsne_feats, final_labels, title='CLIP TSNE Plot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PixelNeRF Feature Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Pixelnerf features. \n",
    "pixelnerf_feats = load_pixelnerf_features(snare_objs)\n",
    "\n",
    "# Filter features by top 10 most occurring categories. \n",
    "final_feats, final_labels = filter_by_top_k(counts, pixelnerf_feats, snare_objs, synsets)\n",
    "\n",
    "# Generate TSNE features. \n",
    "tsne_feats = gen_tsne_feats(final_feats)\n",
    "\n",
    "# Visualize them. \n",
    "gen_plot(tsne_feats, final_labels, title='PixelNeRF TSNE Plot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VLG (LegoFormer) Feature Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load LegoFormer features. \n",
    "legoformer_feats = load_legoformer_features(snare_objs)\n",
    "\n",
    "# Filter features by top 10 most occurring categories. \n",
    "final_feats, final_labels = filter_by_top_k(counts, legoformer_feats, snare_objs, synsets)\n",
    "\n",
    "# Generate TSNE features. \n",
    "tsne_feats = gen_tsne_feats(final_feats)\n",
    "\n",
    "# Visualize them. \n",
    "gen_plot(tsne_feats, final_labels, title='LegoFormer TSNE Plot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Probe Functions and Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class for linear probes. \n",
    "class ProbeDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, feats, labels, idx_dict):\n",
    "        \n",
    "        # List of objects in this dataset split. \n",
    "        self.feats = feats\n",
    "        \n",
    "        # Synset labels for objects. \n",
    "        self.labels = labels\n",
    "        \n",
    "        # Holds ID mappings for labels. \n",
    "        self.idx_dict = idx_dict\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.feats)\n",
    "    \n",
    "    def __getitem__(self, idx): \n",
    "        \n",
    "        # Load object features and label. \n",
    "        feat = torch.Tensor(self.feats[idx]).float()\n",
    "        label = self.idx_dict[self.labels[idx]]\n",
    "        \n",
    "        return feat, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearProbe(nn.Module):\n",
    "    \n",
    "    def __init__(self, feat_dim, n_categories):\n",
    "        super().__init__()\n",
    "        self.feat_dim = feat_dim\n",
    "        self.n_categories = n_categories\n",
    "        \n",
    "        # Simple linear probe. \n",
    "        self.probe = nn.Linear(feat_dim, n_categories)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.probe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop. \n",
    "def train_loop(model, train_dataloader):\n",
    "    \n",
    "    # Initialize optimizer. \n",
    "    optim = torch.optim.Adam(model.parameters())\n",
    "    \n",
    "    # Place model on train mode. \n",
    "    model.train()\n",
    "    \n",
    "    # Do one epoch of updates. \n",
    "    for feats, labels in tqdm(train_dataloader):\n",
    "        \n",
    "        # Put on GPU. \n",
    "        feats = feats.cuda()\n",
    "        labels = labels.cuda()\n",
    "        \n",
    "        # Zero out gradients on optimizer. \n",
    "        optim.zero_grad()\n",
    "        \n",
    "        # Forward pass. \n",
    "        logits = model(feats)\n",
    "        \n",
    "        # Compute CE loss and take update.  \n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        loss.backward()\n",
    "        optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model accuracy on a dataset split. \n",
    "def eval_model(model, loader):\n",
    "    \n",
    "    # Keep track of accuracy across all datapoints. \n",
    "    all_correct = []\n",
    "    \n",
    "    # Place model on eval mode. \n",
    "    model.eval()\n",
    "    \n",
    "    # Go over entire dataset. \n",
    "    with torch.no_grad():\n",
    "        for feats, labels in tqdm(loader):\n",
    "            \n",
    "            # Put on GPU. \n",
    "            feats = feats.cuda()\n",
    "            labels = labels.cuda()\n",
    "            \n",
    "            # Forward pass and prediction. \n",
    "            logits = model(feats)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            \n",
    "            # Compute accuracy across batch and add to list over dataset. \n",
    "            correct = torch.eq(preds, labels).long()\n",
    "            all_correct.append(correct.cpu().numpy())\n",
    "            \n",
    "    # Compute dataset split accuracy. \n",
    "    all_correct = np.concatenate(all_correct)\n",
    "    acc = np.mean(all_correct)\n",
    "    \n",
    "    return acc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training pipeline. \n",
    "def run_probe(model, train_loader, val_loader, test_loader, n_epochs):\n",
    "    \n",
    "    # Keep track of best model checkpoint for test set. \n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for i in range(n_epochs):\n",
    "        \n",
    "        # Do a training iteration with model. \n",
    "        train_loop(model, train_loader)\n",
    "        \n",
    "        # Evaluate model on validation set. \n",
    "        val_acc = eval_model(model, val_loader)\n",
    "        \n",
    "        # Keep best performing model checkpoint. \n",
    "        if val_acc > best_acc: \n",
    "            torch.save(model.state_dict(), 'probe.pth')\n",
    "        \n",
    "        # Print best accuracy. \n",
    "        print('Best Acc: {}'.format(best_acc))\n",
    "            \n",
    "    # Evaluate best checkpoint on test set.\n",
    "    model.load_state_dict(torch.load('probe.pth')) \n",
    "    test_acc = eval_model(model, test_loader)\n",
    "    print('Probe test performance: {}'.format(test_acc))\n",
    "    \n",
    "    # Get rid of probe temp path. \n",
    "    os.remove('probe.path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_probe(snare_objs, counts, synsets, feat_load_func, feat_dim):\n",
    "\n",
    "    # General hyperparameters. \n",
    "    batch_size = 64\n",
    "    n_epochs = 30\n",
    "    n_categories = 10\n",
    "    \n",
    "    # TODO Set GPU number here. \n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "    # Load features and labels.\n",
    "    feats = feat_load_func(snare_objs)\n",
    "\n",
    "    # Filter features by top 10 most occurring categories. \n",
    "    final_feats, final_labels = filter_by_top_k(counts, feats, snare_objs, synsets)\n",
    "\n",
    "    # Compute dataset split lengths. \n",
    "    train_len = int(float(len(final_feats)) * 0.8)\n",
    "    val_len = int(float(len(final_feats)) * 0.1)\n",
    "\n",
    "    # Compute ID dictionary for labels. \n",
    "    label_list = list(synsets)\n",
    "    idx_dict = {label_list[i]: i for i in range(len(label_list))} \n",
    "\n",
    "    # Split into datasets. \n",
    "    train_dataset = ProbeDataset(final_feats[:train_len], final_labels[:train_len], idx_dict)\n",
    "    val_dataset = ProbeDataset(final_feats[train_len:train_len+val_len], final_labels[train_len:train_len+val_len], idx_dict)\n",
    "    test_dataset = ProbeDataset(final_feats[train_len+val_len:], final_labels[train_len+val_len:], idx_dict)\n",
    "\n",
    "    # Form dataloaders. \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Instantiate model. \n",
    "    model = LinearProbe(feat_dim, 10)\n",
    "    model.cuda()\n",
    "    \n",
    "    # Run linear probe. \n",
    "    run_probe(model, train_loader, val_loader, test_loader, n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLIP Linear Probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training CLIP Linear Probe...')\n",
    "linear_probe(snare_objs, counts, synsets, load_clip_features, 512)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('snare_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78dba385ee9abf9152c787729aa5a448da84ca902d6733d7ee16359c358ffbc3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
